{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMEE3NrEgvLT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import PIL.Image\n",
        "import imgaug.augmenters as iaa\n",
        "import tensorflow as tf\n",
        "import mrcnn.utils\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "\n",
        "# Dataset directory\n",
        "dataset_dir = \"data/processed\"\n",
        "\n",
        "# Train directory\n",
        "train_dir = os.path.join(dataset_dir, \"train\")\n",
        "\n",
        "# Validation directory\n",
        "validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "\n",
        "# Test directory\n",
        "test_dir = os.path.join(dataset_dir, \"test\")\n",
        "\n",
        "# Create a directory to store the processed dataset\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# Resize the images and convert polygon annotations to masks\n",
        "annotations_path = \"path/to/annotations.json\"\n",
        "images_dir = \"/path/to/images\"\n",
        "\n",
        "# Load annotations from JSON file\n",
        "with open(annotations_path, \"r\") as file:\n",
        "    annotations = json.load(file)\n",
        "\n",
        "for annotation in annotations:\n",
        "    image_filename = annotation[\"filename\"]\n",
        "    image_path = os.path.join(images_dir, image_filename)\n",
        "    image = PIL.Image.open(image_path)\n",
        "    image = image.resize((224, 224))\n",
        "    image.save(os.path.join(dataset_dir, image_filename))\n",
        "\n",
        "    # Convert polygon annotation to mask\n",
        "    polygons = annotation[\"polygons\"]\n",
        "    mask = mrcnn.utils.polygons_to_mask(image.size[::-1], polygons)\n",
        "    mask_path = os.path.join(dataset_dir, image_filename.replace(\".jpg\", \".png\"))\n",
        "    mask_image = PIL.Image.fromarray(mask.astype(\"uint8\") * 255)\n",
        "    mask_image.save(mask_path)\n",
        "\n",
        "# Augment the data (optional)\n",
        "augmenter = iaa.Fliplr(0.5)\n",
        "for image in os.listdir(train_dir):\n",
        "    if image.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(train_dir, image)\n",
        "        augmented_image = augmenter.augment_image(PIL.Image.open(image_path))\n",
        "        augmented_image.save(image_path)\n",
        "\n",
        "# Create the model configuration\n",
        "class SunglassesConfig(Config):\n",
        "    NAME = \"sunglasses\"\n",
        "    IMAGES_PER_GPU = 2\n",
        "    NUM_CLASSES = 2  # Background + Sunglasses\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "\n",
        "config = SunglassesConfig()\n",
        "\n",
        "# Create the model\n",
        "model = MaskRCNN(mode=\"training\", config=config, model_dir=dataset_dir)\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    train_dir,\n",
        "    validation_dir,\n",
        "    epochs=100,\n",
        "    batch_size=8,\n",
        "    learning_rate=0.0001,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(patience=10, factor=0.1),\n",
        "        tf.keras.callbacks.EarlyStopping(patience=20),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(validation_dir)\n",
        "\n",
        "# Save the model\n",
        "model.save(os.path.join(dataset_dir, \"model.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb"
      ],
      "metadata": {
        "id": "hEqaa-7kg3JL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}